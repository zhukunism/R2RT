{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)\n",
    "\n",
    "# adapted from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/reader.py\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "\n",
    "    # partition raw data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "        data_y[i] = raw_y[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "    # further divide batch partitions into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "\n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps:(i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps:(i + 1) * num_steps]\n",
    "        yield (x, y)\n",
    "\n",
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: W.name=softmax/W:0 b.name=softmax/b:0\n",
      "x <class 'tensorflow.python.framework.ops.Tensor'> (200, 5)\n",
      "y <class 'tensorflow.python.framework.ops.Tensor'> (200, 5)\n",
      "y_as_list <class 'list'> 5\n",
      "\n",
      "EPOCH 0\n",
      "Average loss at step 100 for last 250 steps: 0.648438000679\n",
      "Average loss at step 200 for last 250 steps: 0.548104881048\n",
      "Average loss at step 300 for last 250 steps: 0.520847534239\n",
      "Average loss at step 400 for last 250 steps: 0.52171852082\n",
      "Average loss at step 500 for last 250 steps: 0.521589063704\n",
      "Average loss at step 600 for last 250 steps: 0.519162614048\n",
      "Average loss at step 700 for last 250 steps: 0.522432149649\n",
      "Average loss at step 800 for last 250 steps: 0.519260733426\n",
      "Average loss at step 900 for last 250 steps: 0.520305085182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xd2fa080>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9tx0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xccee3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Global config variables\n",
    "num_steps = 5 # number of truncated backprop steps ('n' in the discussion above)\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "state_size = 4\n",
    "learning_rate = 0.1\n",
    "\n",
    "\"\"\"\n",
    "Placeholders\n",
    "\"\"\"\n",
    "\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "\"\"\"\n",
    "RNN Inputs\n",
    "\"\"\"\n",
    "\n",
    "# Turn our x placeholder into a list of one-hot tensors:\n",
    "# rnn_inputs is a list of num_steps tensors with shape [batch_size, num_classes]\n",
    "x_one_hot = tf.one_hot(x, num_classes)\n",
    "rnn_inputs = tf.unstack(x_one_hot, axis=1)\n",
    "\n",
    "\"\"\"\n",
    "Definition of rnn_cell\n",
    "\n",
    "This is very similar to the __call__ method on Tensorflow's BasicRNNCell. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py#L95\n",
    "\"\"\"\n",
    "\n",
    "useTF = False\n",
    "\n",
    "if useTF:\n",
    "    cell = tf.contrib.rnn.BasicRNNCell(state_size)\n",
    "    rnn_outputs, final_state = tf.contrib.rnn.static_rnn(cell, rnn_inputs, initial_state=init_state)\n",
    "else:\n",
    "    with tf.variable_scope('rnn_cell'):\n",
    "        W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "        b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "    def rnn_cell(rnn_input, state):\n",
    "        with tf.variable_scope('rnn_cell', reuse=True):\n",
    "            W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "            b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "        print(\"rnn_cell: W.name=%s b.name=%s\" % (W.name,b.name))\n",
    "        return tf.tanh(tf.matmul(tf.concat([rnn_input, state], 1), W) + b)\n",
    "    \"\"\"\n",
    "    Adding rnn_cells to graph\n",
    "\n",
    "    This is a simplified version of the \"static_rnn\" function from Tensorflow's api. See:\n",
    "    https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn.py#L41\n",
    "    Note: In practice, using \"dynamic_rnn\" is a better choice that the \"static_rnn\":\n",
    "    https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py#L390\n",
    "    \"\"\"\n",
    "    state = init_state\n",
    "    rnn_outputs = []\n",
    "    for rnn_input in rnn_inputs:\n",
    "        state = rnn_cell(rnn_input, state)\n",
    "        rnn_outputs.append(state)\n",
    "    final_state = rnn_outputs[-1]\n",
    "\n",
    "    print(\"state\", type(state), state.shape)\n",
    "    print(\"init_state\", type(init_state), init_state.shape)\n",
    "    print(\"final_state\", type(final_state), final_state.shape)\n",
    "    print(\"rnn_inputs\",type(rnn_inputs),len(rnn_inputs))\n",
    "    print(\"rnn_outputs\",type(rnn_outputs),len(rnn_outputs))\n",
    "\n",
    "\"\"\"\n",
    "Predictions, loss, training step\n",
    "\n",
    "Losses is similar to the \"sequence_loss\"\n",
    "function from Tensorflow's API, except that here we are using a list of 2D tensors, instead of a 3D tensor. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/loss.py#L30\n",
    "\"\"\"\n",
    "\n",
    "#logits and predictions\n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "print(\"output: W.name=%s b.name=%s\" % (W.name,b.name))\n",
    "logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]\n",
    "predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "\n",
    "# Turn our y placeholder into a list of labels\n",
    "y_as_list = tf.unstack(y, num=num_steps, axis=1)\n",
    "print(\"x\",type(x),x.shape)\n",
    "print(\"y\",type(y),y.shape)\n",
    "print(\"y_as_list\",type(y_as_list),len(y_as_list))\n",
    "\n",
    "#losses and train_step\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit) for \\\n",
    "          logit, label in zip(logits, y_as_list)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)\n",
    "\"\"\"\n",
    "Train the network\n",
    "\"\"\"\n",
    "\n",
    "def train_network(num_epochs, num_steps, state_size, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "            if verbose:\n",
    "                print(\"\\nEPOCH\", idx)\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                tr_losses, training_loss_, training_state, _ = \\\n",
    "                    sess.run([losses,\n",
    "                              total_loss,\n",
    "                              final_state,\n",
    "                              train_step],\n",
    "                                  feed_dict={x:X, y:Y, init_state:training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print(\"Average loss at step\", step,\n",
    "                              \"for last 250 steps:\", training_loss/100)\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "\n",
    "    return training_losses\n",
    "training_losses = train_network(1,num_steps,state_size)\n",
    "plt.plot(training_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
